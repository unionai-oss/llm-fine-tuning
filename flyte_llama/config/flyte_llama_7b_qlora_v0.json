{
    "model_path": "codellama/CodeLlama-7b-hf",
    "output_dir": "./output",
    "checkpoint_dir": null,
    "num_epochs": 20,
    "batch_size": 8,
    "test_size": 0.01,
    "model_max_length": 1024,
    "seed": 41,
    "report_to": "wandb",
    "device_map": "auto",
    "gradient_accumulation_steps": 8,
    "padding": "right",
    "dataloader_num_proc": 8,
    "use_fp16": true,
    "use_4bit": true,
    "use_qlora": true,
    "lora_r": 8,
    "lora_alpha": 16,
    "lora_target_modules": ["q_proj", "k_proj", "v_proj"],
    "lora_dropout": 0.05,
    "debug": false
}
